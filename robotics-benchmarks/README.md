# Robotics Benchmark Challenges
Common methods of measurement are an essential component for collaborative research.  To allow other research teams to interpret and reproduce results, requires transparency in evaluation protocols and infrastructure. Within [Robotics at Google](https://research.google/teams/brain/robotics/), we have selected a list of robotics challenges to act as a stable set of benchmarks for evaluating the progress of our research work.  These selected challenges intentionally span a wide range of complexities to allow a broad spectrum of research approaches and time scales. Some challenges may remain unachievable until new research approaches are uncovered.  Over time, we hope approaches will emerge which can accomplish success on many challenges helping advance the state of general robotics.

# Selection Process
Over 300 proposals were evaluated along several dimensions including (but not limited to): operational feasibility, health & safety, applications, research interests, and complexity.  The selection workgroup, composed of members of the Google teams working on robotics, narrowed the selection to a small initial set.  Since the potential span of robotic behaviors is nearly unbounded, the selection process did not attempt to be exhaustive.  Similarly, robots operating in real-world environments are high dimensional problems. This means it is not possible to make challenges "equal" in complexity or difficulty.  As a result, the selected challenges intentionally include a diversity of complexities allowing measurement across a wide range of research approaches.

# Change Process
Any static list of benchmark definitions can become less useful with time.  As the implementations for either evaluation or solution mature, we will uncover details that were underspecified or not practical to execute as specified.  Additionally, as the state of research advances, certain approaches may overfit to particular definitions making the signal of success less informative for advancing general robotics.  Therefore, this list of benchmark challenges will be reviewed on a regular cadence for modification, addition, or deprecation.  As challenge definitions evolve, we intend to make that information versioned and public.
